{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Finance Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pymongo\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pymongo to set up mongo connection\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.otc_markets\n",
    "\n",
    "# Insert testing tickers into mongoDB\n",
    "#db.most_active.insert({'symbols': 'ABCE'})\n",
    "#db.most_active.insert({'symbols': 'ABEPF'})\n",
    "#db.most_active.insert({'symbols': 'ABMT'})\n",
    "\n",
    "# Link to the master DB and then look within the mongoDB COLLECTION\n",
    "most_actives = db.most_active.find({})\n",
    "\n",
    "# Create empty list to store all symbols stored in the mongoDB\n",
    "symbols = []\n",
    "\n",
    "# Appened empty list with symbols pulled from the mongoDB\n",
    "for most_active in most_actives:\n",
    "    symbols.append(most_active['symbols'])\n",
    "\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create emtpy lists for each key metric datapoint that is being scrapped below\n",
    "previous_close_lst = []\n",
    "avg_volume_lst = []\n",
    "market_cap_lst = []\n",
    "beta_lst = []\n",
    "pe_ratio_lst = []\n",
    "price_estimate_lst = []\n",
    "latest_news_link_lst = []\n",
    "latest_news_head_lst = []\n",
    "sector_lst = []\n",
    "industry_lst = []\n",
    "employees_lst = []\n",
    "\n",
    "# With browser open to the Yahoo Finance webpage loop through all ticker symbols and extract key data\n",
    "for symbol in symbols:\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "    url = 'https://finance.yahoo.com/quote/' + symbol\n",
    "    browser.visit(url)\n",
    "    \n",
    "# Wait for page to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "# Scrape the webpage and collect the key metrics\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    string = 'data-test'\n",
    "    \n",
    "# Try to extract last Close Price, or return an N/A\n",
    "    try:\n",
    "        previous_close = soup.find(attrs={'data-test': 'PREV_CLOSE-value'}).span.text\n",
    "        previous_close = float(previous_close)\n",
    "    except AttributeError:\n",
    "        previous_close = 'N/A'\n",
    "# Try to extract average 3 month trading volume and remove commas, or return an N/A\n",
    "    try:\n",
    "        avg_volume = soup.find(attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}).span.text\n",
    "        avg_volume = float(avg_volume.replace(',',''))\n",
    "    except AttributeError:\n",
    "        avg_volume = 'N/A'\n",
    "# Try to extract market cap of the company, remove commas,\n",
    "# remove letters from million/billion dollar market caps,\n",
    "# then multiply by million or billion to store correct market caps or store an N/A\n",
    "    try:\n",
    "        market_cap = soup.find(attrs={'data-test': 'MARKET_CAP-value'}).span.text\n",
    "        market_cap = market_cap.replace(',','')\n",
    "        if market_cap[-1] == 'M':\n",
    "            market_cap = float(market_cap[:-1]) * 1000000\n",
    "        elif market_cap[-1] == 'B':\n",
    "            market_cap = float(market_cap[:-1]) * 1000000000\n",
    "        else:\n",
    "            market_cap = float(market_cap)\n",
    "    except AttributeError:\n",
    "        market_cap = 'N/A'\n",
    "# Try to extract Beta as float or return an N/A\n",
    "    try:\n",
    "        beta = soup.find(attrs={'data-test': 'BETA_3Y-value'}).span.text\n",
    "        beta = float(beta)\n",
    "    except AttributeError:\n",
    "        beta = 'N/A'\n",
    "# Try to extract Price to Earnings ratio as float or return an N/A\n",
    "    try:\n",
    "        pe_ratio = soup.find(attrs={'data-test': 'PE_RATIO-value'}).span.text\n",
    "        if pe_ratio == 'N/A':\n",
    "            pe_ratio = 'N/A'\n",
    "        else:\n",
    "            pe_ratio = float(pe_ratio)\n",
    "    except AttributeError:\n",
    "        pe_ratio = 'N/A'\n",
    "# Try to extract 1 year Price estimate as float or return an N/A\n",
    "    try:\n",
    "        price_estimate = soup.find(attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}).span.text\n",
    "        if price_estimate == 'N/A':\n",
    "            price_estimate = 'N/A'\n",
    "        else:\n",
    "            price_estimate = float(price_estimate)\n",
    "    except AttributeError:\n",
    "        price_estimate = 'N/A'\n",
    "# Try to extract top news link and header of the article or return an N/A\n",
    "    try:\n",
    "        latest_news_link = 'https://finance.yahoo.com' + soup.find('li', class_='js-stream-content').a['href']\n",
    "    except AttributeError:\n",
    "        latest_news_link = 'N/A'\n",
    "    try:\n",
    "        latest_news_head = soup.find('li', class_='js-stream-content').a.text\n",
    "    except AttributeError:\n",
    "        latest_news_head = 'N/A'\n",
    "        \n",
    "# Test out printing all extracted data   \n",
    "#     print(symbol)\n",
    "#     print(previous_close)\n",
    "#     print(avg_volume)\n",
    "#     print(market_cap)\n",
    "#     print(beta)\n",
    "#     print(pe_ratio)\n",
    "#     print(price_estimate)\n",
    "#     print(latest_news_link)\n",
    "#     print(latest_news_head)\n",
    "    \n",
    "# Command browser to navigate to the Profile page to scrape additional data\n",
    "    browser.click_link_by_partial_text('Profile')\n",
    "    \n",
    "# Wait for page to load\n",
    "    time.sleep(5)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "# Try to find the table with Profile data, if no table present on this page, store N/As \n",
    "    try:\n",
    "        string = soup.find('p', class_='D(ib) Va(t)').text\n",
    "    except AttributeError:\n",
    "        sector = 'N/A'\n",
    "        industry = 'N/A'\n",
    "        employee_count = 'N/A'\n",
    "        \n",
    "# As part of the try loop above, try to find industry, sector, employee count, if nothing found, return N/As\n",
    "# Need to split each string up and separate on a : then grab second index to return actual industry/sector/employees\n",
    "    sector_pos = string.find('Industry')\n",
    "    sector = string[:sector_pos]\n",
    "    if (sector.replace('\\xa0', '').split(':')[1]) == '':\n",
    "        sector = 'N/A'\n",
    "    else:\n",
    "        sector = (sector.replace('\\xa0', '').split(':')[1])\n",
    "    print(sector)\n",
    "    \n",
    "    industry_pos = string.find('Full Time')\n",
    "    industry = string[sector_pos:industry_pos]\n",
    "    if (industry.replace('\\xa0', '').split(':')[1]) == '':\n",
    "        industry = 'N/A'\n",
    "    else:\n",
    "        industry = (industry.replace('\\xa0', '').split(':')[1])\n",
    "    print(industry)\n",
    "    \n",
    "    employees = string[industry_pos:]\n",
    "    if (employees.replace('\\xa0', '').split(':')[1]) == '':\n",
    "        employee_count = 'N/A'\n",
    "    else:\n",
    "        employee_count = int(employees.replace('\\xa0', '').split(':')[1])\n",
    "    print(employees.replace('\\xa0', '').split(':'))\n",
    "    \n",
    "    browser.quit()\n",
    "    \n",
    "# Appened all extracted values into the empty lists\n",
    "    previous_close_lst.append(previous_close)\n",
    "    avg_volume_lst.append(avg_volume)\n",
    "    market_cap_lst.append(market_cap)\n",
    "    beta_lst.append(beta)\n",
    "    pe_ratio_lst.append(pe_ratio)\n",
    "    price_estimate_lst.append(price_estimate)\n",
    "    latest_news_link_lst.append(latest_news_link)\n",
    "    latest_news_head_lst.append(latest_news_head)\n",
    "    sector_lst.append(sector)\n",
    "    industry_lst.append(industry)\n",
    "    employees_lst.append(employee_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with columns for each Key Metric\n",
    "yahooDF = pd.DataFrame(columns = ['symbol', 'previous_close', 'avg_volume', 'market_cap', 'beta', 'pe_ratio', 'price_estimate', 'latest_news_link', 'latest_news_head', 'sector', 'industry', 'employees'])\n",
    "\n",
    "# Assign values to columns created in DF above\n",
    "yahooDF['symbol'] = symbols\n",
    "yahooDF['previous_close'] = previous_close_lst \n",
    "yahooDF['avg_volume'] = avg_volume_lst \n",
    "yahooDF['market_cap'] = market_cap_lst\n",
    "yahooDF['beta'] = beta_lst\n",
    "yahooDF['pe_ratio'] = pe_ratio_lst\n",
    "yahooDF['price_estimate'] = price_estimate_lst \n",
    "yahooDF['latest_news_link'] = latest_news_link_lst\n",
    "yahooDF['latest_news_head'] = latest_news_head_lst\n",
    "yahooDF['sector'] = sector_lst\n",
    "yahooDF['industry'] =industry_lst \n",
    "yahooDF['employees'] = employees_lst\n",
    "\n",
    "# Display DF\n",
    "yahooDF.head()\n",
    "\n",
    "# Write DF to a CSV file\n",
    "file_path = os.path.join('data','yahoo_financial_data.csv')\n",
    "yahooDF.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop old DB in order to create a new one\n",
    "db.yahoo_finance_data.drop()\n",
    "\n",
    "# Convert DF to JSON to store in mongoDB\n",
    "records = json.loads(yahooDF.T.to_json()).values()\n",
    "\n",
    "# Insert dataframe as a JSON into mongoDB\n",
    "db.yahoo_finance_data.insert(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
