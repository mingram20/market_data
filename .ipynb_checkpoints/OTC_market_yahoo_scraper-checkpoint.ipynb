{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo Finance Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pymongo\n",
    "import json\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pymongo to set up mongo connection\n",
    "conn = \"mongodb://localhost:27017\"\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.otc_market_finance_data\n",
    "\n",
    "# Link to the master DB and then look within the mongoDB COLLECTION\n",
    "most_actives = db.otc_market_most_active_stocks.find({})\n",
    "\n",
    "# Create empty list to store all symbols stored in the mongoDB\n",
    "symbols = []\n",
    "\n",
    "# Appened empty list with symbols pulled from the mongoDB\n",
    "for most_active in most_actives:\n",
    "    symbols.append(most_active['SYMBOL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Yahoo Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping company number 1: RHHBY.\n",
      "Scraping company number 2: GBTC.\n",
      "Scraping company number 3: FMCKJ.\n",
      "Scraping company number 4: FNMAS.\n",
      "Scraping company number 5: CURLF.\n",
      "Scraping company number 6: DTEGY.\n",
      "Scraping company number 7: RHHVF.\n",
      "Scraping company number 8: OGRMF.\n",
      "Scraping company number 9: CVSI.\n",
      "Scraping company number 10: FERGY.\n"
     ]
    }
   ],
   "source": [
    "# Use this line to limit the number of companies to scrape\n",
    "number_of_companies_to_run = 10\n",
    "symbols = symbols[:number_of_companies_to_run]\n",
    "\n",
    "# Create emtpy lists for each key metric datapoint that is being scrapped below\n",
    "previous_close_lst = []\n",
    "avg_volume_lst = []\n",
    "market_cap_lst = []\n",
    "beta_lst = []\n",
    "pe_ratio_lst = []\n",
    "price_estimate_lst = []\n",
    "latest_news_link_lst = []\n",
    "latest_news_head_lst = []\n",
    "sector_lst = []\n",
    "industry_lst = []\n",
    "employees_lst = []\n",
    "companies_counter = 1\n",
    "\n",
    "# With browser open to the Yahoo Finance webpage loop through all ticker symbols and extract key data\n",
    "for symbol in symbols:\n",
    "    print(f\"Scraping company number {companies_counter}: {symbol}.\")\n",
    "    \n",
    "    # Using Selenium to open browser connection to Yahoo Finance Page\n",
    "    driver = webdriver.Chrome('/usr/local/bin/chromedriver')\n",
    "    url = 'https://finance.yahoo.com/quote/' + symbol\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "    \n",
    "# Wait for page to load\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    \n",
    "# Scrape the webpage and collect the key metrics\n",
    "    string = 'data-test'\n",
    "    \n",
    "# Try to extract last Close Price, or return an N/A\n",
    "    try:\n",
    "        previous_close = soup.find(attrs={'data-test': 'PREV_CLOSE-value'}).span.text\n",
    "        previous_close = float(previous_close)\n",
    "    except AttributeError:\n",
    "        previous_close = 'N/A'\n",
    "# Try to extract average 3 month trading volume and remove commas, or return an N/A\n",
    "    try:\n",
    "        avg_volume = soup.find(attrs={'data-test': 'AVERAGE_VOLUME_3MONTH-value'}).span.text\n",
    "        avg_volume = float(avg_volume.replace(',',''))\n",
    "    except AttributeError:\n",
    "        avg_volume = 'N/A'\n",
    "# Try to extract market cap of the company, remove commas,\n",
    "# remove letters from million/billion dollar market caps,\n",
    "# then multiply by million or billion to store correct market caps or store an N/A\n",
    "    try:\n",
    "        market_cap = soup.find(attrs={'data-test': 'MARKET_CAP-value'}).span.text\n",
    "        market_cap = market_cap.replace(',','')\n",
    "        if market_cap[-1] == 'M':\n",
    "            market_cap = float(market_cap[:-1]) * 1000000\n",
    "        elif market_cap[-1] == 'B':\n",
    "            market_cap = float(market_cap[:-1]) * 1000000000\n",
    "        else:\n",
    "            market_cap = float(market_cap)\n",
    "    except AttributeError:\n",
    "        market_cap = 'N/A'\n",
    "# Try to extract Beta as float or return an N/A\n",
    "    try:\n",
    "        beta = soup.find(attrs={'data-test': 'BETA_3Y-value'}).span.text\n",
    "        if beta != 'N/A':\n",
    "            beta = float(beta)\n",
    "    except AttributeError:\n",
    "        beta = 'N/A'\n",
    "# Try to extract Price to Earnings ratio as float or return an N/A\n",
    "    try:\n",
    "        pe_ratio = soup.find(attrs={'data-test': 'PE_RATIO-value'}).span.text\n",
    "        pe_ratio = pe_ratio.replace(',','')\n",
    "        if pe_ratio == 'N/A':\n",
    "            pe_ratio = 'N/A'\n",
    "        else:\n",
    "            pe_ratio = float(pe_ratio)\n",
    "    except AttributeError:\n",
    "        pe_ratio = 'N/A'\n",
    "# Try to extract 1 year Price estimate as float or return an N/A\n",
    "    try:\n",
    "        price_estimate = soup.find(attrs={'data-test': 'ONE_YEAR_TARGET_PRICE-value'}).span.text\n",
    "        if price_estimate == 'N/A':\n",
    "            price_estimate = 'N/A'\n",
    "        else:\n",
    "            price_estimate = float(price_estimate)\n",
    "    except AttributeError:\n",
    "        price_estimate = 'N/A'\n",
    "# Try to extract top news link and header of the article or return an N/A\n",
    "    try:\n",
    "        latest_news_link = 'https://finance.yahoo.com' + soup.find('li', class_='js-stream-content').a['href']\n",
    "    except AttributeError:\n",
    "        latest_news_link = 'N/A'\n",
    "    try:\n",
    "        latest_news_head = soup.find('li', class_='js-stream-content').a.text\n",
    "    except AttributeError:\n",
    "        latest_news_head = 'N/A'      \n",
    "        \n",
    "    # Test out printing all extracted data   \n",
    "    # print(previous_close)\n",
    "    # print(avg_volume)\n",
    "    # print(market_cap)\n",
    "    # print(beta)\n",
    "    # print(pe_ratio)\n",
    "    # print(price_estimate)\n",
    "    # print(latest_news_link)\n",
    "    # print(latest_news_head)\n",
    "    \n",
    "# Open Yahoo Profile page to scrape additional data\n",
    "    \n",
    "    url = url + '/profile?p=' + symbol\n",
    "    driver.get(url)\n",
    "    \n",
    "# Wait for page to load\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    \n",
    "# As part of the try loop above, try to find industry, sector, employee count, if nothing found, return N/As\n",
    "# Need to split each string up and separate on a : then grab second index to return actual industry/sector/employees\n",
    "\n",
    "    try:\n",
    "        string = soup.find('p', class_='D(ib) Va(t)').text\n",
    "        \n",
    "        sector_pos = string.find('Industry')\n",
    "        sector = string[:sector_pos]\n",
    "        if (sector.replace('\\xa0', '').split(':')[1]) == '':\n",
    "            sector = 'N/A'\n",
    "        else:\n",
    "            sector = (sector.replace('\\xa0', '').split(':')[1])\n",
    "        #print(sector)\n",
    "\n",
    "        industry_pos = string.find('Full Time')\n",
    "        industry = string[sector_pos:industry_pos]\n",
    "        if (industry.replace('\\xa0', '').split(':')[1]) == '':\n",
    "            industry = 'N/A'\n",
    "        else:\n",
    "            industry = (industry.replace('\\xa0', '').split(':')[1])\n",
    "        #print(industry)\n",
    "\n",
    "        employees = string[industry_pos:]\n",
    "        if (employees.replace('\\xa0', '').split(':')[1]) == '':\n",
    "            employee_count = 'N/A'\n",
    "        else:\n",
    "            employees = employees.replace(',', '').split(':')[1]\n",
    "            employee_count = int(employees.replace('\\xa0', ''))\n",
    "        #print(employees.replace('\\xa0', '').split(':'))\n",
    "    except AttributeError:\n",
    "        sector = 'N/A'\n",
    "        industry = 'N/A'\n",
    "        employee_count = 'N/A'\n",
    "\n",
    "    # Close the browser window\n",
    "    driver.quit()\n",
    "    \n",
    "# Appened all extracted values into the empty lists\n",
    "    previous_close_lst.append(previous_close)\n",
    "    avg_volume_lst.append(avg_volume)\n",
    "    market_cap_lst.append(market_cap)\n",
    "    beta_lst.append(beta)\n",
    "    pe_ratio_lst.append(pe_ratio)\n",
    "    price_estimate_lst.append(price_estimate)\n",
    "    latest_news_link_lst.append(latest_news_link)\n",
    "    latest_news_head_lst.append(latest_news_head)\n",
    "    sector_lst.append(sector)\n",
    "    industry_lst.append(industry)\n",
    "    employees_lst.append(employee_count)\n",
    "    \n",
    "    companies_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe to store Yahoo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new DataFrame with columns for each Key Metric\n",
    "yahooDF = pd.DataFrame(columns = ['symbol', 'previous_close', 'avg_volume', 'market_cap', 'beta', 'pe_ratio', 'price_estimate', 'latest_news_link', 'latest_news_head', 'sector', 'industry', 'employees'])\n",
    "\n",
    "# Assign values to columns created in DF above\n",
    "yahooDF['symbol'] = symbols\n",
    "yahooDF['previous_close'] = previous_close_lst \n",
    "yahooDF['avg_volume'] = avg_volume_lst \n",
    "yahooDF['market_cap'] = market_cap_lst\n",
    "yahooDF['beta'] = beta_lst\n",
    "yahooDF['pe_ratio'] = pe_ratio_lst\n",
    "yahooDF['price_estimate'] = price_estimate_lst \n",
    "yahooDF['latest_news_link'] = latest_news_link_lst\n",
    "yahooDF['latest_news_head'] = latest_news_head_lst\n",
    "yahooDF['sector'] = sector_lst\n",
    "yahooDF['industry'] =industry_lst \n",
    "yahooDF['employees'] = employees_lst\n",
    "\n",
    "# Display DF\n",
    "yahooDF.head()\n",
    "\n",
    "# Write DF to a CSV file\n",
    "file_path = os.path.join('data','yahoo_financial_data.csv')\n",
    "yahooDF.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Yahoo data in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ObjectId('5ccdc83c247ac635645edf71'),\n",
       " ObjectId('5ccdc83c247ac635645edf72'),\n",
       " ObjectId('5ccdc83c247ac635645edf73'),\n",
       " ObjectId('5ccdc83c247ac635645edf74'),\n",
       " ObjectId('5ccdc83c247ac635645edf75'),\n",
       " ObjectId('5ccdc83c247ac635645edf76'),\n",
       " ObjectId('5ccdc83c247ac635645edf77'),\n",
       " ObjectId('5ccdc83c247ac635645edf78'),\n",
       " ObjectId('5ccdc83c247ac635645edf79'),\n",
       " ObjectId('5ccdc83c247ac635645edf7a')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop old DB in order to create a new one\n",
    "db.otc_market_yahoo_data.drop()\n",
    "\n",
    "# Convert DF to JSON to store in mongoDB\n",
    "records = json.loads(yahooDF.T.to_json()).values()\n",
    "\n",
    "# Insert dataframe as a JSON into mongoDB\n",
    "db.otc_market_yahoo_data.insert(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
